% Chapter Chapter 7 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 11 June 2014

<<set-parent7, echo=FALSE, results='hide', cache=FALSE>>=
set_parent('Rep-Res-Parent.Rnw')
@

\chapter{Preparing Data for Analysis}\label{DataClean}

Once we have gathered the raw data that we want to include in our statistical analyses we generally need to clean it up so that it can be merged it into a single data file. In this chapter we will learn how to create the data gather and merging files we saw in the last chapter. The chapter also includes information on recoding and transforming variables. This is important for merging data, but will be very useful information in later chapters as well. If you are very familiar with data transformations in R you may want to skip onto the next chapter.

\section{Cleaning Data for Merging}

In order to successfully merge two or more data frames we need to make sure that they are in the same format. Let's look at some of the important formatting issues and how to reformat your data frames so that they can be easily merged.

\subsection{Get a handle on your data}

Before doing anything to your data it is a good idea to take a look at it and see what needs to be done. Taking a little time to become acquainted with your data will help you avoid many error messages and much frustration.

You could of course just type a data frame object's name into the R console. This will print the entire data frame in your console. For data frames with more than a few variables and observations this is very impractical. We have already seen a number of commands that are useful for looking at parts of your data. As we saw in Chapter \ref{GettingStartedRKnitr}, the \texttt{names}\index{R command!names} command shows you the variable names in a data frame object. The \texttt{head}\index{R command!head} command shows the names plus the first few observations in a data frame. The \texttt{tail}\index{R command!tail} shows the last few.

Use the \texttt{dim}\index{R command!dim} (dimensions) command to quickly see the number of observations and variables (the number of rows and columns) in a data frame object. For example, let's use the \emph{FertConsumpData} object we created in Chapter \ref{DataGather} to test out \texttt{dim}:

<<Ch7dim>>=
dim(FertConsumpData)
@

\noindent The first number is the number of rows in the data frame (\Sexpr{dim(FertConsumpData)[[1]]}) and the second is the number of columns (\Sexpr{dim(FertConsumpData)[[2]]}). You can also use the \texttt{nrow} command to find just the number of rows and \texttt{ncol} to see only the columns.\index{R command!nrow}\index{R command!ncol}

The \texttt{summary} command\index{R command!summary} is especially helpful for seeing basic descriptive statistics for all of the variables in a data frame and also the variables' types. Here is an example:

{\small
<<Ch7SummaryExamp>>=
# Summarize FertConsumpData data frame object
# This was loaded in Chapter 6
summary(FertConsumpData)
@
}

\noindent We can immediately see that the variables \textbf{iso2c} and \textbf{country} are character strings. Because \texttt{summary} is able to calculate means, medians, and so on for \textbf{AG.CON.FERT.ZS} and \textbf{year}, we know they are numeric. Have a look over the summary to see if there is anything unexpected like lots of missing values (\textbf{NA's}) or unusual maximum and minimum values. You can of course run \texttt{summary} on a particular variable by using the component selector (\verb|$|):

<<Ch7SummarizeCompSelect>>=
# Summarize fertilizer consumption variable from FertConsumpData
summary(FertConsumpData$AG.CON.FERT.ZS)
@

\noindent We'll come back to why knowing this type of information is important for merging and data analysis later in this chapter.

Another important command for quickly summarizing a data frame is \texttt{table}.\index{R command!table} This creates a contingency table\index{contingency table} with counts of the number of observations per combination of factor variables.

You can view a portion of a data frame object with the \texttt{View} command.\index{R command!View} This will open a new window that lets you see a selection of the data frame. If you are using RStudio, you can click on the data frame in the \emph{Workspace} tab\index{RStudio!Workspace tab} and you will get something similar. Note that neither of these viewers are interactive in that you can't use them to manipulate the data. They are only data viewers. To be able to see similar windows that you can interactively edit use the \texttt{fix}\index{R command!fix} command in the same way that you use \texttt{View}. This can be useful for small edits, but remember that the edits are not reproducible.

\subsection{Reshaping data}\index{R!reshaping data}

Obviously it is usually a good idea if your data sets are kept in data frame type objects. See Chapter \ref{GettingStartedRKnitr} (Section \ref{data.frame}) for how to convert objects into data frames with the \texttt{data.frame} command.\index{R command!data.frame}\index{R!data frame} Not only do data sets (generally) need to be stored in data frame objects, they also need to have the same layout before they can be merged. Most R statistical analysis tools assume that your data is in ``long'' format\index{long formatted data}. This usually means that data frame columns are variables and rows are specific observations (see Table \ref{ExampleLong}).

\begin{table}[h!]
    \caption{Long Formatted Data Example}
    \label{ExampleLong}
    \begin{tabular}{l c}
        \\[0.15cm]
        \hline
        Subject & Variable1 \\
        \hline \\[0.1cm]
        Subject1 & \\[0.25cm]
        Subject2 & \\[0.25cm]
        Subject3 & \\[0.25cm]
        \ldots & \\[0.25cm]
        \hline
    \end{tabular}
\end{table}

\noindent In this chapter we will mostly use examples of time-series cross-sectional data (TSCS)\index{time-series cross-sectional}\index{TSCS} that we want to have in long-format. Long formatted TSCS data is simply a data frame where rows identify observations of a particular subject at particular points in time (see Table \ref{ExampleTSCSLong}). In this chapter our TSCS data is specifically going to be countries that are observed in multiple years.


 \begin{table}[h!]
    \caption{Long Formatted Time-series Cross-sectional Data Example}
    \label{ExampleTSCSLong}
    \begin{tabular}{l c c}
        \\[0.15cm]
        \hline
        Subject & Time & Variable1 \\
        \hline \\[0.1cm]
        Subject1 & 1 & \\[0.25cm]
        Subject1 & 2 & \\[0.25cm]
        Subject1 & 3 & \\[0.25cm]
        Subject2 & 1 & \\[0.25cm]
        Subject2 & 2 & \\[0.25cm]
        Subject2 & 3 & \\[0.25cm]
        \ldots & & \\[0.25cm]
        \hline
    \end{tabular}
\end{table}

If one of our raw data sets is not in this format then we will need to reshape\index{reshape data} it. Some data sets are in ``wide'' format,\index{wide formatted data} where one of the columns in long formatted data is widened to cover multiple columns. This is confusing to visualize without an example. Table \ref{ExampleWide} shows how Table \ref{ExampleTSCSLong} looks when we widen the time variable.

\begin{table}[h!]
    \caption{Wide Formatted Data Example}
    \label{ExampleWide}
    \begin{tabular}{l c c c}
        \\[0.15cm]
        \hline
        Subject & Time1 & Time2 & Time3 \\
        \hline \\[0.1cm]
        Subject1 & & & \\[0.25cm]
        Subject2 & & & \\[0.25cm]
        \ldots & & & \\[0.25cm]
        \hline
    \end{tabular}
\end{table}

Reshaping data is often the cause of much confusion and frustration. Though probably never easy, there are a number of useful R functions for changing data from wide format to long and vice versa. These include the matrix transpose command (\textbf{t})\footnote{See this example by Rob Kabacoff: \url{http://www.statmethods.net/management/reshape.html}. Note also that because the matrix transpose function is denoted with \texttt{t}, you should not give any object the name \emph{t}.}\index{matrix transpose} and the \texttt{reshape}\index{R command!reshape} command, both are loaded in R by default. \emph{reshape2} is a very helpful package for reshaping data \citep{R-reshape2}.\index{reshape2}\footnote{Note: confusingly the \emph{reshape2} package does not include the \texttt{reshape} command. The \texttt{reshape} command is part of R's built in \emph{stats} package.\index{stats} I don't cover that command here, because it is less flexible than what \emph{reshape2} can do.} This provides more general tools for reshaping data and is worth investing some time to learn well. In this section we will cover some of \emph{reshape2}'s basic commands and use them to reshape a TSCS data frame from wide to long format. We will also encounter this package again in Chapter \ref{FiguresChapter} when we want to transform data so that it can be graphed.

Let's imagine that the fertilizer consumption data we previously downloaded from the World Bank is in wide rather than long format and is in a data frame objected called \emph{WideFert}. It looks like this:\footnote{Please see the chapter's Appendix (page \pageref{WideAppendix}) for the code I used to reshape the data from wide to long format.}

<<Ch7LoadFertConsumpData, include=FALSE>>=

@

<<Ch7WideCreate, include=FALSE>>=
# Reshape Wide
MoltenFert <- melt(data = FertConsumpData,
                    id.vars = c("iso2c", "country", "year"),
                    measure.vars= "AG.CON.FERT.ZS")

# Cast MoltenFert to year wide format
WideFert <- dcast(data = MoltenFert,
                    formula = iso2c + country ~ year,
                    value.var = "value")

# Order Wide Fert by country
WideFert <- WideFert[order(WideFert$country), ]
@

<<Ch7ShowWideFert>>=
# Show the first 7 columns
head(WideFert[, 1:7])
@

\noindent We can use \emph{reshape2}'s \texttt{melt}\index{melt}\index{R command!melt}\label{MeltReshape} command to reshape this data from wide to long format. The term ``melt'' is intended to evoke an image of the data melting down from a wide to long format.\footnote{The opposite \texttt{cast} command (\texttt{dcast}\index{cast}\index{R command!dcast}\index{dcast}\index{R command!dcast} in the case of data frames) is supposed to evoke an image of casting out the data from long to wide format. See Section \ref{WideAppendix} for an example using the \texttt{dcast} command.} In our \emph{WideFert} data we don't want the \textbf{iso2c} and \textbf{country} variables to be melted. These variables identify the data set's subjects. We can tell \texttt{melt} that they are id variables with the \texttt{id.vars} argument. The remaining columns (i.e. \textbf{2002}, \textbf{2003}, \textbf{2004} and \textbf{2005}) will be melted into two new variables: \textbf{variable}, and \textbf{value}. The former will contain the years and the later will contain the fertilizer consumption data. Here is the full code:

<<Ch7MeltFert, tidy=FALSE>>=
# Melt WideFert
MoltenFert <- melt(data = WideFert,
                    id.vars = c("iso2c", "country"))

# Show MoltenFert
head(MoltenFert)
@

\noindent Objects created by \texttt{melt} are often referred to as ``molten'' data in the \emph{reshape2} documentation. That is why I've given our new data frame the name \emph{MoltenFert}.

\subsection{Renaming variables}\index{R!renaming variables}

Frequently, in the data clean up process we want to change the names of our variables. This will make our data easier to understand and may even be necessary to properly combine data sets (see below). In the previous example, for instance, our \emph{MoltenFert} data frame has two variables--\textbf{variable} and \textbf{value}--that would be easier to understand if they were renamed \textbf{year} and \textbf{FertilizerConsumption}. Renaming data frame variables is straightforward with the \texttt{rename}\index{R command!rename} command in the \emph{plyr} package \citep{R-plyr}.

To rename both \textbf{variable} and \textbf{value} with the \texttt{rename} command type:

<<Ch7Rename, tidy=FALSE>>=
# Rename variable = year, value = FertilizerConsumption
MoltenFert <- plyr::rename(x = MoltenFert,
                replace = c("variable" = "year",
                            "value" = "FertilizerConsumption"))

# Show MoltenFert
head(MoltenFert)
@

\subsection{Ordering data}\index{R!ordering data}

You may have noticed that as a result of melting \emph{WideFert} the data is now ordered by year then country name. Typically TSCS data is sorted by country then year, or more generally: subject-year. Though not required for merging in R\footnote{Unlike in other statistical programs.} some statistical analyses assume that the data is ordered in a specific way. Well-ordered data is also easier for people to read.

We can order observations in our data set using the \texttt{order} command.\index{R command!order}\index{sort}\index{order} For example, to order \emph{MoltenFert} by country-year we type:

<<Ch7Order, tidy=FALSE>>=
# Order MoltenFert by country-year
MoltenFert <- MoltenFert[order(MoltenFert$country,
                                MoltenFert$year), ]

# Show MoltenFert
head(MoltenFert)
@

\subsection{Subsetting data}\index{R!subsetting data}

Sometimes you may want to use only a subset of a data frame. For example, the density plot in Figure \ref{FertilizerConsumptionDens} shows us that the \emph{MoltenFert} data has a few very extreme values. We can use the \texttt{subset}\index{subset}\index{R command!subset} command to examine these outliers,\index{outliers} for example countries that have fertilizer consumption greater than 1000 kilograms per hectare.

\begin{figure}
    \caption{Density Plot of Fertilizer Consumption (kilograms per hectare of arable land)}
    \label{FertilizerConsumptionDens}
<<Ch7FertDist, echo=FALSE, warning=FALSE, fig.width=3, fig.height=3>>=
# Create density plot of MoltenFert

# Load ggplot2
library(ggplot2)

# Create histogram
ggplot(data = MoltenFert, aes(FertilizerConsumption)) +
        geom_density() +
        xlab("\n Fertilizer Consumption") + ylab("Density\n") +
        theme_bw()
@
    {\scriptsize{See the Chapter's Appendix for the source code to create this figure.}}
\end{figure}

{\small
<<Ch7SubsetOutliers, tidy=FALSE>>=
# Create outlier data frame
FertOutliers <- subset(x = MoltenFert,
                        FertilizerConsumption > 1000)

# Show FertOutliers
FertOutliers
@
}

\noindent If we want to drop these outliers from our data set we can use \texttt{subset} again.

<<Ch7SubsetNoOutliers, tidy=FALSE>>=
MoltenFertSub <- subset(x = MoltenFert,
                        FertilizerConsumption <= 1000)
@

In this data example, non-country units like ``Arab World'' are included. We might want to drop these units with the \texttt{subset} command as well. For example:

<<Ch7DropString, tidy=FALSE>>=
# Drop Arab World type from MoltenFertSub
MoltenFertSub <- subset(x = MoltenFertSub,
                        country != "Arab World")
@

\noindent We can also use \texttt{subset} to remove observations with missing values (\texttt{NA}) for \textbf{FertilizerConsumption}.

<<Ch7IsNotNA, tidy=FALSE>>=
# Remove observations of FertilizerConsumption
# with missing values
MoltenFertSub <- subset(x = MoltenFertSub,
                             !is.na(FertilizerConsumption))

# Summarize FertilizerConsumption
summary(MoltenFertSub$FertilizerConsumption)
@

\begin{table}
    \caption{R's Logical Operators}
    \label{LogicalOp}
    \begin{center}
    \begin{tabular}{l c}
        \hline\vspace{0.15cm}
        Operator & Meaning \\
        \hline\hline \\
        \verb|<| & less than \\
        \verb|>| & greater than \\
        \verb|==| & equal to \\
        \verb|<=| & less than or equal to \\
        \verb|>=| & greater than or equal to \\
        \verb|!=| & not equal to \\
        \verb+a | b + & a or b \\
        \verb|a & b| & a \& b \\
        \verb|isTRUE(a)| & determine if a is TRUE \\
        \hline \\
        \verb|is.na| & missing\\
        \verb|!is.na| & not missing \\
        \verb|duplicated| & duplicated observation \\
        \verb|!duplicated| & not a duplicated observation \\
        \hline
    \end{tabular}
    \end{center}
\end{table}

Let's step back one second. I've introduced a number of new logical operators\index{R!logical operators} and a new command in the four subsetting examples. The first example included a very simple one, the greater than sign (\verb|>|). The second example included the less than or equal to operator: \verb|<=|. The third example included the not equal operator: \verb|!=|.\index{R!not equal} In R exclamation points (\verb|!|) generally denote `not'.\index{R!exclamation point} We used this again in the final example in combination with the \texttt{is.na} command.\index{R command!is.na} This command indicates if an element is missing, so \verb|!is.na| means ``not missing''. For the full list of R's logical operators see Table \ref{LogicalOp}. You can use these operators and commands when subsetting data and throughout R.

\subsection{Recoding string/numeric variables}\index{R!recode}

You may want to recode your variables. In particular when you merge data sets together you need to have \textbf{identical} identification values that R can use to match each observation on. If in one data set observations for the Republic of Korea\index{Republic of Korea} are referred to as ``Korea, Rep.'' and in another they are labeled ``South Korea'', R will not know to merge them. We need to recode values in the variables that we want to match our data sets on. For example, in \emph{MoltenFertSub} the southern Korean country is labeled ``Korea, Rep.''. To recode it to ``South Korea'' we type:

<<Ch7RecodeString, tidy=FALSE>>=
# Recode country == "Korea, Rep."" to "South Korea"
MoltenFertSub$country[MoltenFertSub$country ==
                        "Korea, Rep."] <- "South Korea"
@

\noindent This code assigns ``South Korea'' to all values of the \textbf{country} variable that equal ``Korea, Rep.''.\footnote{The \emph{countrycode} package \citep{R-countrycode}\index{countrycode} is very helpful for creating standardized country identification variables.} You can use a similar technique to recode numeric variables as well. The only difference is that you omit the quotation marks. We will look at how to code factor variables later.

\subsection{Creating new variables from old}

As part of your data clean up process (or later during statistical analysis) you may want to create new variables based on existing variables. For example, we could create a new variable that is the natural logarithm of \textbf{FertilizerConsumption}. To do this we run the variable through the \texttt{log}\index{R command!log}\index{log} command and assign a new variable that we'll call \textbf{logFertConsumption}.

{\small
<<Ch7LogFertComsump, tidy=FALSE>>=
MoltenFertSub$logFertConsumption <- log(
                            MoltenFertSub$FertilizerConsumption
                            )

# Summarize the log transformed variable
summary(MoltenFertSub$logFertConsumption)
@
}

\noindent We can use a similar procedure to create new variables from R's many other mathematical commands and arithmetic operations.\footnote{E.g \texttt{+, -, *, /, \^} for addition, subtraction, multiplication, division, and exponentiation, respectively.\index{R!addition}\index{R!subtraction}\index{R!multiplication}\index{R!division}\index{R!exponentiation}}

\label{Infinity}Notice that when we summarize the new log transformed variable that we have a minimum (and mean) value of \texttt{-Inf}.\index{R!-Inf}\index{infinity} This indicates that by logging the variable we have created observations with the value negative infinity. R calculates the natural logarithm of zero as negative infinity.\footnote{R denotes positive infinity with \texttt{Inf}.\index{positive infinity}\index{R!Inf}}\index{negative infinity} We probably don't want negative infinity values. There are a few ways to deal with this. We could drop all observations of \textbf{FertilizerConsumption} with the value zero before log transforming it. Another common solution is recoding zeros as some small nonnegative number like 0.001. For example:

{\small
<<Ch7LogFertComsumpAgain, tidy=FALSE>>=
# Recode zeros in Fertilizer Consumption
MoltenFertSub$FertilizerConsumption[
                        MoltenFertSub$FertilizerConsumption == 0
                        ] <- 0.001

# Natural log transform Fertilizer Consumption
MoltenFertSub$logFertConsumption <- log(
                        MoltenFertSub$FertilizerConsumption
                        )

# Summarize the log transformed variable
summary(MoltenFertSub$logFertConsumption)
@
}


\begin{table}
    \caption{Example Factor Levels}
    \label{ExampleFactorRecode}
    \begin{center}
        \begin{tabular}{l l p{4cm}}
            \hline
            Number & Label & Value of \textbf{FertilizerConsumption} \\
            \hline\hline \\
            1 & low & $< 15$ \\
            2 & medium low & $\ge 15$ \& $< 80$ \\
            3 & medium high & $\ge 80$ \& $< 150$ \\
            4 & high & $\ge 150$ \\
            \hline
        \end{tabular}
    \end{center}
\end{table}

\paragraph{Creating factor variables}\index{R!factors}

We can create factor variables from numeric or string variables. For example, we may want to turn the continuous numeric \textbf{FertilizerConsumption} variable into an ordered categorical (i.e. factor) variable.\index{factor variable} Imagine that we want to create a factor variable called \textbf{FertConsGroup} with four levels called `low', `medium low', `medium high', `high'. To do this let's first create a new numeric variable based on the values listed in Table \ref{ExampleFactorRecode}. Now let's use a procedure that is similar to the variable recoding we did earlier:\footnote{In this code I attached the data frame \emph{MoltenFertSub}\index{R command!attach} so that it is easier to read.\index{R!attach}}

<<Ch7FactorNumeric, tidy=FALSE>>=
#### Create numeric factor levels variable ####
# Attach MoltenFertSub data frame
attach(MoltenFertSub)

# Created new FertConsGroup variable based on
# FertilizerConsumption
MoltenFertSub$FertConsGroup[FertilizerConsumption
                            < 15] <- 1
MoltenFertSub$FertConsGroup[FertilizerConsumption
                            >= 15 &
                            FertilizerConsumption < 80] <- 2
MoltenFertSub$FertConsGroup[FertilizerConsumption
                            >= 80 &
                            FertilizerConsumption < 150] <- 3
MoltenFertSub$FertConsGroup[FertilizerConsumption
                            >= 150] <- 4
MoltenFertSub$FertConsGroup[is.na(FertilizerConsumption)] <- NA

# Detach data frame
detach(MoltenFertSub)

# Summarize FertConsGroup
summary(MoltenFertSub$FertConsGroup)
@

\noindent You'll notice that we don't have a factor variable yet; our new variable is numeric. We can use the \texttt{factor} command\index{R command!factor} to convert \emph{FertConsGroup} into a factor variable with the labels we want.\index{R!factor labels}

<<Ch7ChangetoFactor, tidy=FALSE>>=
# Create vector of factor level labels
FCLabels <- c("low", "medium low", "medium high", "high")

# Convert FertConsGroup to a factor
MoltenFertSub$FertConsGroup <- factor(MoltenFertSub$FertConsGroup,
                                        labels = FCLabels)

# Summarize FertConsGroup
summary(MoltenFertSub$FertConsGroup)
@

\noindent We first created a character vector with the factor level labels and then applied using \texttt{factor}'s \texttt{labels} argument. Using \texttt{summary}\index{R command!summary} with a factor variable gives us its level labels as well as the number of observations per level.

The \texttt{cut} command \index{R command!cut} provides a less code intensive way of creating factors from numeric ones and labelling factor levels. For example:

<<Ch7Cut, tidy=FALSE>>=
# Create a factor variable with the cut command
FertFactor <- cut(MoltenFertSub$FertilizerConsumption,
                  breaks = c(-0.01, 14.99, 80, 150, 1000),
                  labels = c("low", "medium low",
                             "medium high", "high"))

# Summarize FertFactor
summary(FertFactor)
@

\noindent The \texttt{labels} argument lets us specify the factor levels' names. The \texttt{breaks} argument lets us specify at what values separate the factor levels. Note that we set the first break as \texttt{-0.01}, not because any country had negative fertilizer consumption, but because the intervals created by \texttt{break} exclude the left value and include the right value.\footnote{In mathematical notation the ``low'' level includes all values in the interval $(-0.01,\:14.99]$.} If we had used \texttt{0} then all of the observations where a country used effectively no fertilizer would be excluded from the ``low'' category.

\subsection{Changing variable types}\index{R!change variable type}

Sometimes a variable will have the wrong type. For example, a numeric variable may be incorrectly made a character string when a data set is imported from Excel. You can change variables' types with a number of commands. We already saw how to convert a numeric variable to a factor variable with the \texttt{factor}\index{R command!factor} command. Unsurprisingly, to convert a variable to a character use \texttt{character}\index{R command!character} and \texttt{numeric}\index{R command!numeric} to convert it to a numeric type variable. We can place \texttt{as.} before these commands (e.g. \texttt{as.factor})\index{R command!as.factor}\index{R command!as.} as a way of coercing a change in type.\index{R!coercion}

\textbf{Warning:} Though these commands have straightforward names, a word of caution is necessary. Always try to understand why a variable is not of the type you would expect. Often times variables have unexpected types because they are coded (or miscoded) in a way that you didn't anticipate. Changing the variables' types, especially when using \texttt{as.}, can introduce new errors. Make sure that the conversion made the changes you expected.

\section{Merging Data Sets}\index{R!merging}\index{merge}

In the previous section we learned crucial skills for cleaning up data sets. When your data sets are (a) in the same format and (b) have variables with identically matching ID values you can merge your data sets together. In this section we'll look at two different ways to merge data sets: binding and the \texttt{merge} command. We'll also look at ways to address a common issue when merging data: duplicated observations and columns.

\subsection{Binding}\index{R!binding}

As we saw in Chapter \ref{GettingStartedRKnitr}, if your data sets are in the same order--rows in all of the data sets represent the same observation of the same subject--then you can simply use the \texttt{cbind}\index{R command!cbind} command to bind columns from the data sets together. This situation is unusual when merging real-world data. If your data sets are not in exactly the same order you will create a data set with nonsensical rows that combine data from multiple observations. Therefore, you should avoid using \texttt{cbind} for merging most real-world data.

If you have data sets with the exact same columns and variable types and you just want to attach one under the other you can use the \texttt{rbind}\index{rbind} command. It binds the rows in one object to the rows in another.\footnote{Some statistical programs refer to this type of action as ``appending''\index{append} one data set to another.} It has the same syntax as \texttt{cbind} (see page \pageref{cbind}). Again, you should be cautious when using this command, though it is more difficult to accidentally create a nonsensical data set with \texttt{rbind}. R will give you an error if it cannot match your objects' columns.

\subsection{The merge command}

Generally, the safest and most effective way to merge two data sets together is with the \texttt{merge}\index{merge}\index{R command!merge} command. Imagine that we want to merge our \emph{MoltenFertSub} data frame with two other data frames we created in Chapter \ref{DataGather}: \emph{FinRegulatorData} and \emph{DispropData}. The simplest way to do this is to use the merge command twice, i.e.:

<<Ch7AddIsoCodes, include=FALSE>>=
## Add iso2c codes to FinRegulatorData and DispropData
## as ID variables for merging

# Load countrycode
library(countrycode)

# FinRegulatorData
FinRegulatorData$iso2c <- countrycode(FinRegulatorData$country,
                                    origin = "country.name",
                                    destination = "iso2c")

# DispropData
DispropData$iso2c <- countrycode(DispropData$country,
                                    origin = "country.name",
                                    destination = "iso2c")
@

<<Ch7MergeSimple, tidy=FALSE>>=
# Merge FinRegulatorData and DispropData
MergedData1 <- merge(x = FinRegulatorData,
                     y = DispropData,
                     by = "iso2c",
                     all = TRUE)

# Merge combined data set with and MoltenFertSub
MergedData1 <- merge(x = MergedData1,
                     y = MoltenFertSub,
                     by = "iso2c",
                     all = TRUE)

# Show MergedData1 variables
names(MergedData1)
@

\noindent Let's go through this code. The \texttt{x} and \texttt{y} arguments simply specify which data frames we want to merge. The \texttt{by} argument specifies what variable in the two frames identify the observations so that we can match them. In this example we are merging by countries' ISO country two letter codes.\footnote{Please see this chapter's Appendix for details on how I created ISO country two letter code variables in the \emph{DispropData} and \emph{FinRegulatorData} data frames.} We set the argument \texttt{all = TRUE} so that we keep all of the observations from both of the data frames. If the argument is set to \texttt{FALSE} only observations that are common to both data frames will be included in the merged data frame. The others will not be included.

You might have noticed that this isn't actually the merge that we want to accomplish with these data frames. Remember that observations are not simply identified in this time-series cross-section data by one country name or other country code variable. Instead they are identified by both country and year variables. To merge data frames based on the overlap of two variables (e.g. match Afghanistan-2004 in one data frame with Afghanistan-2004 in the other) we need to add the \texttt{union}\index{R!command} command to \texttt{merge}'s \texttt{by} argument. Here is a full example:\footnote{You can download a modified version of this example as part of the makefile exercise from Chapter \ref{DataGather}: \url{http://bit.ly/YnMKBG}.}

<<Ch7MergeFull, tidy=FALSE>>=
# Merge FinRegulatorData and DispropData
MergedData2 <- merge(FinRegulatorData, DispropData,
                    union("iso2c", "year"),
                    all = TRUE)

# Merge combined data frame with MoltenFertSub
MergedData2 <- merge(MergedData2, MoltenFertSub,
                    union("iso2c", "year"),
                    all = TRUE)

# Show MergedData2 variable names
names(MergedData2)
@


After merging data frames it is always a good idea to look at the result and make sure it is what you expected. Some post merging clean up may be required to get the data frame ready for statistical analysis.

\paragraph{Big data}\index{big data}

Before discussing post-merge clean up it is important to highlight ways to handle large data sets. The \texttt{merge} command and many of the other data frame manipulation commands covered so far in this chapter may not perform well with very large data sets. If you are using very large data sets it might be worth investing time learning how to use the \emph{data.table} package \citep{R-data.table}. Another approach is to learn SQL\footnote{Structured Query Language}\index{SQL}\index{Structured Query Language} or another special purpose data handling language.\footnote{w3schools has an online SQL tutorial at: \url{http://www.w3schools.com/sql/default.asp}.} Once you know how these languages work, you can incorporate them into your R workflow with R packages like \emph{sqldf} \citep{R-sqldf}.\footnote{J.D. Long has a blog post on how to load large data sets into R using \emph{sqldf}: \url{http://www.cerebralmastication.com/2009/11/loading-big-data-into-r/} (posted 24 November 2009).}

\subsection{Duplicate values}

Duplicate observations are one thing to look out for after (and before) merging. You can use the \texttt{duplicated}\index{R command!duplicated}\index{R!duplicates} command to check for duplicates. Use the command in conjunction with subscripts to remove duplicate observations. For example, let's create a new object called \emph{DataDuplicates} from the iso2c-years that are duplicated in \emph{MergedData2}. Remember that \textbf{iso2c} and \textbf{year} are in the first and second columns of the data frame.

<<Ch7Duplicated, tidy=FALSE>>=
# Created a data frame of duplicated country-years
DataDuplicates <- MergedData2[duplicated(
                                MergedData2[, 1:2]), ]

# Show the number of rows in DataDuplicates
nrow(DataDuplicates)
@

\noindent In this data frame there are \Sexpr{nrow(DataDuplicates)} duplicated iso2c-year observations. We know this because \texttt{nrow}\index{R command!nrow} tells us that the data frame with the duplicated values has \Sexpr{nrow(DataDuplicates)} rows, i.e. \Sexpr{nrow(DataDuplicates)} observations.

To create a data set without duplicated observations (if there are duplicates) we just add an exclamation point (\texttt{!}) before \texttt{duplicated}--i.e. not duplicated--in the above code.

<<Ch7NotDuplicated, tidy=FALSE>>=
# Created a data frame of unique country-years
DataNotDuplicates <- MergedData2[!duplicated(
                                MergedData2[, 1:2]), ]
@

\noindent Note that if you do have duplicated values in your data set and you run a similar procedure on it, it will drop duplicated values that have a lower order in the data frame. To keep the lowest ordered value and drop duplicates higher in the data set use \texttt{duplicated}'s \texttt{fromLast} argument like this: \texttt{fromLast = TRUE}.

\textbf{Warning:} look over your data set and the source code that created the data set to try to understand why duplicates occurred. There may be a fundamental problem in the way you are handling your data that resulted in the duplicated observations.

\subsection{Duplicate columns}\index{R!duplicate variables}

Another common post-merge clean up issue is duplicate variables. These are variables from the two data frames with the same name that were not included in \texttt{merge}'s \texttt{by} argument. For example, in our previous merged data examples there are three country name variables: \textbf{country.x}, \textbf{country.y}, and \textbf{country} to signify which data frame they are from.\footnote{The former two were created in the first merge between \emph{FinRegulatorData} and \emph{DispropData}. When the second merge was completed there were no variables named \textbf{country} in the MergeData2 data frame, so \textbf{country} did not need to be renamed in the new merged data set.}

You should of course decide what to do with these variables on a case-by-case basis. But if you decide to drop one of the variables and rename the other, you can use subscripts (as we saw in Chapter \ref{GettingStartedRKnitr}). The \emph{gdata}\index{gdata} package \citep{R-gdata} has a useful function called \texttt{remove.vars}\index{R command!remove.vars} that can also remove variables from data frames. For example, imagine that we want to keep \textbf{country.x} and drop the other variables.\footnote{This version of the country variable is the most complete.} Let's also remove another unwanted variable as well, the extraneous \textbf{idn} variable:

<<Ch7RemoveVars, tidy=FALSE>>=
# Remove country.y, country, and idn
FinalCleanedData <- gdata::remove.vars(data = DataNotDuplicates,
                                names = c("country.y",
                                        "country",
                                        "idn"))

# Rename country.x = country
FinalCleanedData <- plyr::rename(FinalCleanedData,
                            replace = c("country.x" =
                                        "country"))
@

{\footnotesize
<<Ch7ShowFinalCleanedDataNames>>=
# Show FinalCleanedData variables
names(FinalCleanedData)
@
}

\noindent Note if you are merging many data sets it can sometimes be good to clean up duplicate columns between each \texttt{merge} call.

\subsection*{Chapter Summary}

This chapter has provided you with many tools for cleaning up your data to get it ready for statistical analysis. Before moving on to the next chapter to learn how to incorporate statistical analysis as part of a reproducible workflow with \emph{knitr}, it's important to reiterate that the commands we've covered in this chapter should usually be embedded in the types of data creation files we saw in Chapter \ref{DataGather}. These files can then be tied together with a makefile into a process that should be able to relatively easily take very raw data and clean it up for use in your analyses. Embedding these commands in data creation source code files, rather then just typing the commands into your R Console\index{R!Console} or manually changing data in Excel, will make your research much more reproducible. It will also make it easier to backtrack and find mistakes that you may have made while transforming the data. Including new or updated data when it becomes available will also be much easier if you use a series of segmented data creation source code files that are tied together with a makefile.

\section*{Appendix}\label{WideAppendix}

R code for turning \emph{FertConsumData} into year-wide format:

<<Ch7WideCreateShow, eval=FALSE, tidy=FALSE>>=
# Load WDI and reshape2 package
library(WDI)
library(reshape2)

# Gather fertilizer consumption data from WDI
FertConsumpData <- WDI(indicator = "AG.CON.FERT.ZS")

# Melt data
## Note: data must be melted before it can be cast.
MoltenFert <- melt(data = FertConsumpData,
                    id.vars = c("iso2c", "country", "year"),
                    measure.vars= "AG.CON.FERT.ZS")

# Cast MoltenFert to year wide format
WideFert <- dcast(MoltenFert,
                  formula = iso2c + country ~ year,
                  value.var = "value")

# Order WideFert by country
WideFert <- WideFert[order(WideFert$country), ]
@

R code for creating iso2c country codes with the \emph{countrycode} package:\label{CountryCodeExample}

<<Ch7CountryCodeShow, eval=FALSE, tidy=FALSE>>=
# Load countrycode package
library(countrycode)

# FinRegulatorData
FinRegulatorData$iso2c <- countrycode(FinRegulatorData$country,
                                    origin = "country.name",
                                    destination = "iso2c")

# DispropData
DispropData$iso2c <- countrycode(DispropData$country,
                                    origin = "country.name",
                                    destination = "iso2c")
@

R code for creating Figure \ref{FertilizerConsumptionDens}:

<<Chr7FigDensity, eval=FALSE, tidy=FALSE>>=
# Load ggplot2
library(ggplot2)

# Create density plot
ggplot(data = MoltenFert, aes(FertilizerConsumption)) +
        geom_density() +
        xlab("\n Fertilizer Consumption") + ylab("Density\n") +
        theme_bw()
@
